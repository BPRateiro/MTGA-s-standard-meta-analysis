{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from time import sleep"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Request\n",
    "\n",
    "Some structures used during requests are found below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevant data is found in two different URLs\n",
    "urls = {\n",
    "    'api': 'https://api.mtga.untapped.gg/api/v1/',\n",
    "    'json': 'https://mtgajson.untapped.gg/v1/latest/',\n",
    "}\n",
    "\n",
    "# We read four JSONs in total. The following dictionary facilitates access to its endpoints.\n",
    "# json: (url, endpoint) \n",
    "endpoints = {\n",
    "    'active': ('api', 'meta-periods/active'),\n",
    "    'analytics': ('api', 'analytics/query/card_stats_by_archetype_event_and_scope_free/ALL?MetaPeriodId='),\n",
    "    'cards': ('json', 'cards.json'),\n",
    "    'text': ('json', 'loc_en.json'),\n",
    "}\n",
    "\n",
    "# Header information\n",
    "headers = {\n",
    "    'authority': 'api.mtga.untapped.gg',\n",
    "    'accept': '*/*',\n",
    "    'accept-language': 'en-US,en;q=0.9,pt;q=0.8',\n",
    "    'if-none-match': '\"047066ff947f01e9e609ca4cf0d6c0a6\"',\n",
    "    'origin': 'https://mtga.untapped.gg',\n",
    "    'referer': 'https://mtga.untapped.gg/',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"111\", \"Not(A:Brand\";v=\"8\", \"Chromium\";v=\"111\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "@lru_cache\n",
    "def request(keyword, send_headers=True, format=''):\n",
    "    'Returns JSON from the corresponding keyword'\n",
    "    url_kw, endpoint = endpoints[keyword]\n",
    "    url = urls[url_kw]\n",
    "\n",
    "    sleep(2) # Resonable interval betwween requests\n",
    "\n",
    "    try:\n",
    "        if send_headers:\n",
    "            response = requests.get(url+endpoint+format, headers)\n",
    "        else:\n",
    "            response = requests.get(url+endpoint+format)\n",
    "\n",
    "    except requests.exceptions.RequestException as error:\n",
    "        raise error\n",
    "    \n",
    "    else:\n",
    "        return response.json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Active JSON\n",
    "\n",
    "We need to find what's the current active standard format to compose the analytics request.\n",
    "We also get all the legal set codes contained in this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 ['MID', 'VOW', 'NEO', 'SNC', 'DMU', 'BRO', 'ONE', 'MOM']\n"
     ]
    }
   ],
   "source": [
    "def request_active():\n",
    "    'Returns format ID and lists of standard legal sets'\n",
    "\n",
    "    # Extracting information from the latest standard BO1 format\n",
    "    for format in reversed(request('active')):\n",
    "        if format['event_name'] == 'Ladder':\n",
    "            return str(format['id']), format['legal_sets']\n",
    "\n",
    "format_id, legal_sets = request_active()\n",
    "print(format_id, legal_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cards JSON\n",
    "\n",
    "We only bother to keep card information from the legal sets.\n",
    "\n",
    "A card can be reprinted, i.e. a card from an older set could be reprinted in newer sets.\n",
    "Untapped chooses to group all cards with the same title indicated by `grpid`, but for the sake of simplicity, we choose to only consider the latest reprint.\n",
    "\n",
    "`raw_card` is a data frame containing card information with minimal modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_cards(sets):\n",
    "    'Returns raw card data frame'\n",
    "    df = pd.DataFrame(request('cards'))\n",
    "\n",
    "    # Ony bother with standard legal cards\n",
    "    df = df[df.set.isin(sets)]\n",
    "\n",
    "    # Remove duplicates by considering only the latest reprint\n",
    "    gb = df.groupby('titleId').agg({'grpid':'max'})\n",
    "    df = df[df.grpid.isin(gb.grpid)]\n",
    "\n",
    "    return df.set_index('grpid')\n",
    "\n",
    "raw_card = request_cards(legal_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics JSON\n",
    "\n",
    "`raw_analytics` contains daily games information separated by tiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_analytics(format):\n",
    "    'Returns raw analytics data frame'\n",
    "    json = request('analytics', False, format)\n",
    "\n",
    "    return pd.json_normalize(json['data']).T\n",
    "\n",
    "raw_analytics = request_analytics(format_id)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text JSON\n",
    "\n",
    "All text used to build the web table is contained here, including card text.\n",
    "\n",
    "`raw_text` is a data frame containing all text with minimal modifications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_text():\n",
    "    'Returns raw card text data frame'\n",
    "    df = pd.DataFrame(request('text')).set_index('id')\n",
    "\n",
    "    # Collapse columns raw and text, prioritizing raw\n",
    "    df.loc[~df.raw.isna(), 'text'] = df.raw\n",
    "    df.drop('raw', axis='columns', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "raw_text = request_text()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get functions\n",
    "\n",
    "After requesting all JSONs, we have to filter and normalize the data, which in this case results in multiple dataframes.\n",
    "\n",
    "### Card information\n",
    "\n",
    "The main function in the following block is `get_card_information()`. It gets data from `raw_card` and combines with relevant text from `text`. Normalization results in the following data frames with respective schema:\n",
    "\n",
    "- `card`:\n",
    "    - `card_id` (Integer PK): corresponding to `titleId` in JSON\n",
    "    - `art_id` (Integer): art id in case I find a way to get images\n",
    "    - `set_id` (String): three-letter set identifier\n",
    "    - `title` (String): name of the card, necessarily unique\n",
    "    - `rarity` (String): rarity of a card\n",
    "    - `power` (String): creature power. Can be an integer, null or '*'\n",
    "    - `toughness` (String): creature toughness. Can be an integer, null or '*'\n",
    "    - `flavor` (String): flavor text, if a card has any\n",
    "    - `is_legendary` (Boolean): flags a card is legendary\n",
    "    - `is_token` (Boolean): flags a card token\n",
    "    - `is_secondary_card` (Boolean): Flags a card secondary in an archetype\n",
    "    - `is_rebalanced` (Boolean): Flags a digitally rebalanced card\n",
    "- `card_type`:\n",
    "    - `card_id` (Integer FK): corresponding to `titleId` in JSON\n",
    "    - `type` (String PK): type according to magic rules\n",
    "- `card_subtype`:\n",
    "    - `card_id` (Integer FK): corresponding to `titleId` in JSON\n",
    "    - `subtype` (String PK): subtype according to magic rules\n",
    "- `card_cost`:\n",
    "    - `card_id` (Integer FK): corresponding to `titleId` in JSON\n",
    "    - `color` (String PK): six color identifiers according to magic rules\n",
    "    - `cost` (Integer): amount of mana to be paid of given color\n",
    "- `card_ability`\n",
    "    - `card_id` (Integer FK): corresponding to `titleId` in JSON\n",
    "    - `ability` (String): ability raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_raw_card(raw_card):\n",
    "    \"Change naming conventions and keep only relevant columns before normalization\"\n",
    "\n",
    "    keep = [\n",
    "        'titleId',\n",
    "        'art_id',\n",
    "        'flavorId',\n",
    "        'power',\n",
    "        'toughness',\n",
    "        'set_id',\n",
    "        'castingcost',\n",
    "        'rarity',\n",
    "        'cardTypeTextId',\n",
    "        'subtypeTextId',\n",
    "        'ability',\n",
    "        'is_secondary_card',\n",
    "        'is_token',\n",
    "        'is_rebalanced'\n",
    "    ]\n",
    "\n",
    "    rename = {\n",
    "        'set':'set_id',\n",
    "        'isSecondaryCard': 'is_secondary_card',\n",
    "        'isToken': 'is_token',\n",
    "        'IsRebalanced': 'is_rebalanced',\n",
    "        'artId': 'art_id',\n",
    "        'abilities': 'ability'\n",
    "    }\n",
    "\n",
    "    return raw_card.rename(rename, axis = 'columns').reset_index()[keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_dataframe(df):\n",
    "    \"Returns card dataframe\"   \n",
    "\n",
    "    # Card columns mappable to text\n",
    "    id_to_text = ['titleId', 'flavorId', 'cardTypeTextId', 'subtypeTextId']\n",
    "\n",
    "    # Additional text_columns columns\n",
    "    df = df.join(\n",
    "        df[id_to_text]\n",
    "        .applymap(lambda x: raw_text.loc[x].values[0], na_action='ignore')\n",
    "        .rename(columns={column: column[:-2] for column in id_to_text}) # Remove Id\n",
    "    )\n",
    "\n",
    "    # Only tracked supertype will be 'legendary'\n",
    "    df['is_legendary'] = df.cardTypeText.str.contains('Legendary')\n",
    "\n",
    "    # Replace empty string flavor with NaN\n",
    "    df.flavor = df.flavor.replace({'': np.nan})\n",
    "\n",
    "    # Replace rarity id with text\n",
    "    df.rarity = df.rarity.replace ({1: 'Common',\n",
    "                                    2: 'Common',\n",
    "                                    3: 'Uncommon',\n",
    "                                    4: 'Rare',\n",
    "                                    5: 'Mythic Rare'})\n",
    "\n",
    "    # Define the columns and order for card data frame\n",
    "    order = [\n",
    "        'titleId',\n",
    "        'art_id',\n",
    "        'set_id',\n",
    "        'title',\n",
    "        'rarity',\n",
    "        'power',\n",
    "        'toughness',\n",
    "        'flavor',\n",
    "        'is_legendary',\n",
    "        'is_token',\n",
    "        'is_secondary_card',\n",
    "        'is_rebalanced',\n",
    "    ]\n",
    "\n",
    "    return df[order]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_type(df):\n",
    "    'Returns card type data frame'\n",
    "    # Convert 'cardTypeTextId' to text\n",
    "    df = df.join(df.cardTypeTextId\n",
    "                   .map(lambda x: raw_text.loc[x].values[0], na_action='ignore')\n",
    "                   .rename('type'))\n",
    "    \n",
    "    # Split the text and transform it into a list of rows, deleting the ones without information\n",
    "    df = df.type.str.split().explode().dropna()\n",
    "\n",
    "    # There are special cases of cards not having types such as cards 'Day' and 'Night'\n",
    "    df = df[~df.isin(['NONE', 'Legendary', 'Basic', 'Token'])]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_subtype(df):\n",
    "    \"Returns card subtype data frame\"\n",
    "    # Convert 'subtypeTextId' to text\n",
    "    df = df.join(df.subtypeTextId\n",
    "                   .map(lambda x: raw_text.loc[x].values[0], na_action='ignore')\n",
    "                   .rename('subtype'))\n",
    "\n",
    "    # Split the text and transform it into a list of rows, deleting the ones without information\n",
    "    df = df.subtype.str.split().explode().dropna()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_cost(df):\n",
    "    \"Returns card cost data frame\"\n",
    "    # Casting color codes in 'castingcost' column\n",
    "    casting_colors = {\n",
    "        'Black': r'oB',\n",
    "        'Blue': r'oU',\n",
    "        'Green': r'oG',\n",
    "        'Red': r'oR',\n",
    "        'White': r'oW',\n",
    "        'Multicolor': r'\\(',\n",
    "        'X': r'oX'\n",
    "    }\n",
    "\n",
    "    # Create a column for each variety\n",
    "    for color, code in casting_colors.items():\n",
    "        df[color] = df.castingcost.str.count(code)\n",
    "\n",
    "    # Special case is colorless that can be any number\n",
    "    df['Colorless'] = df.castingcost.str.extract(r'(\\d+)')\n",
    "\n",
    "    # Stack columns into rows and set index to card_id only\n",
    "    df = (df[['Colorless'] + list(casting_colors.keys())].stack()\n",
    "                                                         .reset_index()\n",
    "                                                         .set_index('card_id')\n",
    "                                                         .rename(columns={'level_1': 'color', 0: 'cost'}))\n",
    "\n",
    "    df.cost = pd.to_numeric(df.cost) # Convert from string to number\n",
    "\n",
    "    # Only record costs above zero\n",
    "    return df[df.cost > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_ability(df):\n",
    "    'Returns card_ability data frame'\n",
    "    df = (df.ability\n",
    "            .dropna()\n",
    "            .explode()\n",
    "            .apply(lambda x: x.get('TextId'))\n",
    "            .map(lambda x: raw_text.loc[x].values[0]))      \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_information():\n",
    "    'Returns multiple data frames containing card information after normalization'\n",
    "    filtered = filter_raw_card(raw_card)\n",
    "    card = get_card_dataframe(filtered)\n",
    "\n",
    "    # Rename 'titleId' to 'card_id' and promote it to index\n",
    "    for df in [filtered, card]:\n",
    "        df.set_index('titleId', inplace=True)\n",
    "        df.index.name = 'card_id'\n",
    "\n",
    "    card_type = get_card_type(filtered)\n",
    "    card_subtype = get_card_subtype(filtered)\n",
    "    card_cost = get_card_cost(filtered)\n",
    "    card_ability = get_card_ability(filtered)\n",
    "\n",
    "    return card, card_type, card_subtype, card_cost, card_ability\n",
    "\n",
    "card, card_type, card_subtype, card_cost, card_ability = get_card_information()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics\n",
    "\n",
    "The main function in the following block is `get_analytics()`. It gets data from `raw_analytics`. Normalization results in the following data frames with respective schema:\n",
    "\n",
    "- `analytics_games`: Defined by `card_id`, `tier` and `copies`\n",
    "    - `card_id` (Integer FK): corresponding to `titleId` in JSON\n",
    "    - `tier` (String PK): game tier, from bronze to platinum\n",
    "    - `copies` (Integer PK): number of copies, between 1 and 4\n",
    "    - `games`(Integer): number of games\n",
    "- `analytics_wins`: Defined by `card_id` and `tier`\n",
    "    - `card_id` (Integer FK): corresponding to `titleId` in JSON\n",
    "    - `tier` (String PK): game tier, from bronze to platinum\n",
    "    - `wins` (Integer): number of games resulting in victory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_raw_analytics():\n",
    "    # Reset index and rename tiers\n",
    "    df = (raw_analytics.reset_index()\n",
    "                       .rename(columns={'index':'raw'}))\n",
    "    \n",
    "    # Split raw column into multiple\n",
    "    df[['card_id', 'archetype_id', 'tier']] = df.raw.str.split('.', expand=True)\n",
    "\n",
    "    # Record only consolidated data by archetype and change index to titleId\n",
    "    df = (df[df.archetype_id == 'ALL']\n",
    "            .drop(['raw', 'archetype_id'], axis=1)\n",
    "            .set_index('card_id'))\n",
    "    \n",
    "    # Replace abbreviations with tier full names\n",
    "    df.replace({'b': 'Bronze',\n",
    "                's': 'Silver',\n",
    "                'g': 'Gold',\n",
    "                'p': 'Platinum'},\n",
    "               inplace = True)\n",
    "\n",
    "    # Unnest statistics\n",
    "    unnest = ['games', 'wins', 'check', 'copies']\n",
    "    df[unnest] = pd.DataFrame(df.explode([0])[0].to_list(), index=df.index).iloc[:, :4]\n",
    "\n",
    "    return df[['tier', 'wins', 'copies']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_tiered_daily_games(df):\n",
    "    \"Returns data frame 'analytics_games'\"\n",
    "    # Unnest copies\n",
    "    unnest = [1, 2, 3, 4]\n",
    "    df[unnest] = pd.DataFrame(df.copies.to_list(), index=df.index)\n",
    "\n",
    "    df = (df.reset_index()\n",
    "            .melt(id_vars = ['card_id', 'tier'],\n",
    "                  value_vars = unnest,\n",
    "                  var_name = 'copies',\n",
    "                  value_name = 'games')\n",
    "            .set_index('card_id')\n",
    "            .dropna())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analytics():\n",
    "    \"Returns both 'analytics_games' and 'analytics_wins'\"\n",
    "    filtered = filter_raw_analytics()\n",
    "\n",
    "    analytics_wins = filtered[['tier', 'wins']]\n",
    "    analytics_games = get_card_tiered_daily_games(filtered)\n",
    "    \n",
    "    return analytics_wins, analytics_games\n",
    "\n",
    "analytics_wins, analytics_games = get_analytics()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

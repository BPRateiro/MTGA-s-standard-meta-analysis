{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from time import sleep\n",
    "\n",
    "urls = {\n",
    "    'api' : 'https://api.mtga.untapped.gg/api/v1/',\n",
    "    'json' : 'https://mtgajson.untapped.gg/v1/latest/',\n",
    "}\n",
    "\n",
    "endpoints = {\n",
    "    'active': ('api', 'meta-periods/active'),\n",
    "    'tags': ('api', 'tags'),\n",
    "    'archetypes': ('api', 'analytics/query/archetypes_by_event_scope_and_rank?MetaPeriodId=334&RankingClassScopeFilter=BRONZE_TO_PLATINUM'),\n",
    "    'analytics': ('api', 'analytics/query/card_stats_by_archetype_event_and_scope_free/ALL?MetaPeriodId=334'),\n",
    "    'cards': ('json', 'cards.json'),\n",
    "    'text': ('json', 'loc_en.json'),\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'authority': 'api.mtga.untapped.gg',\n",
    "    'accept': '*/*',\n",
    "    'accept-language': 'en-US,en;q=0.9,pt;q=0.8',\n",
    "    'if-none-match': '\"047066ff947f01e9e609ca4cf0d6c0a6\"',\n",
    "    'origin': 'https://mtga.untapped.gg',\n",
    "    'referer': 'https://mtga.untapped.gg/',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"111\", \"Not(A:Brand\";v=\"8\", \"Chromium\";v=\"111\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "def request_json(keyword, send_headers=True):\n",
    "    'Returns JSON from corresponding keyword'\n",
    "\n",
    "    url_kw, endpoint = endpoints[keyword]\n",
    "    url = urls[url_kw]\n",
    "    \n",
    "    sleep(2)\n",
    "    if send_headers:\n",
    "        return requests.get(url+endpoint, headers).json()\n",
    "    else:\n",
    "        return requests.get(url+endpoint).json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_legal_sets():\n",
    "    'Returns lists of standard legal sets'\n",
    "    latest = dict()\n",
    "\n",
    "    # Extracting information from the lastest standard BO1 format\n",
    "    for format in request_json('active'):\n",
    "        if format['event_name'] == 'Ladder':\n",
    "            latest = format\n",
    "\n",
    "    return latest['legal_sets']\n",
    "\n",
    "# get_legal_sets()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cards():\n",
    "    'Returns transformed cards dataframe'\n",
    "    df = pd.DataFrame(request_json('cards'))\n",
    "\n",
    "    # Ony bother with standard legal cards\n",
    "    df = df[df.set.isin(get_legal_sets())]\n",
    "\n",
    "    # Remove duplicates by considering only the latest reprint\n",
    "    gb = df.groupby('titleId').agg({'grpid':'max'})\n",
    "    df = df[df.grpid.isin(gb.grpid)]\n",
    "    # print(df.titleId.is_unique)\n",
    "\n",
    "    return df.set_index('grpid')\n",
    "\n",
    "# cards = get_cards()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text():\n",
    "    'Returns card text dataframe'\n",
    "\n",
    "    df = pd.DataFrame(request_json('text')).set_index('id')\n",
    "\n",
    "    # Collapse columns raw and text, prioritizing raw\n",
    "    df.loc[~df.raw.isna(), 'text'] = df.raw\n",
    "    df.drop('raw', axis='columns', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "# text = get_text()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Card information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_information():\n",
    "    text = get_text()\n",
    "    cards = get_cards()\n",
    "\n",
    "    # Card columns mappable to text\n",
    "    text_columns = ['titleId', 'flavorId', 'cardTypeTextId', 'subtypeTextId']\n",
    "\n",
    "    # Additional transformed columns\n",
    "    transformed = (\n",
    "        cards[text_columns]\n",
    "        .applymap(lambda x: text.loc[x].values[0], na_action='ignore')\n",
    "        .rename(columns={column: column[:-2] for column in text_columns}) # Remove Id\n",
    "    )\n",
    "    cards = cards.join(transformed)\n",
    "\n",
    "    # Remove undesirable columns\n",
    "    cards = cards.dropna(how='all', axis='columns')\n",
    "    ignore = [ # These don't seem useful\n",
    "        'collectorMax', \n",
    "        'frameColors',\n",
    "        'rawFrameDetails',\n",
    "        'frameDetails',\n",
    "    ]\n",
    "    problematic = [ # Still work to be done here\n",
    "        'abilities', \n",
    "        'abilityIdToLinkedTokenGrpId', \n",
    "        'hiddenAbilities',\n",
    "        'types',\n",
    "        'subtypes',\n",
    "        'supertypes',\n",
    "        'colors',\n",
    "        'colorIdentity',\n",
    "        'linkedFaces',\n",
    "    ]\n",
    "    cards = cards.drop(ignore + problematic, axis = 'columns')\n",
    "\n",
    "    return cards\n",
    "\n",
    "card_information = get_card_information()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 2158 entries, 78323 to 87130\n",
      "Data columns (total 25 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   titleId             2158 non-null   int64  \n",
      " 1   artId               2158 non-null   int64  \n",
      " 2   flavorId            2158 non-null   int64  \n",
      " 3   artistCredit        2156 non-null   object \n",
      " 4   power               1274 non-null   object \n",
      " 5   toughness           1305 non-null   object \n",
      " 6   set                 2158 non-null   object \n",
      " 7   collectorNumber     2158 non-null   object \n",
      " 8   castingcost         1864 non-null   object \n",
      " 9   rarity              2093 non-null   float64\n",
      " 10  cardTypeTextId      2158 non-null   int64  \n",
      " 11  subtypeTextId       1501 non-null   float64\n",
      " 12  altDeckLimit        5 non-null      float64\n",
      " 13  linkedFaceType      283 non-null    float64\n",
      " 14  isSecondaryCard     651 non-null    object \n",
      " 15  isToken             65 non-null     object \n",
      " 16  IsDigitalOnly       89 non-null     object \n",
      " 17  watermark           76 non-null     object \n",
      " 18  RebalancedCardLink  178 non-null    float64\n",
      " 19  altTitleId          7 non-null      float64\n",
      " 20  IsRebalanced        89 non-null     object \n",
      " 21  title               2158 non-null   object \n",
      " 22  flavor              2158 non-null   object \n",
      " 23  cardTypeText        2158 non-null   object \n",
      " 24  subtypeText         1501 non-null   object \n",
      "dtypes: float64(6), int64(4), object(15)\n",
      "memory usage: 502.9+ KB\n"
     ]
    }
   ],
   "source": [
    "card_information.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "titleId               2158\n",
       "artId                 2069\n",
       "flavorId              1015\n",
       "artistCredit           487\n",
       "power                   12\n",
       "toughness               15\n",
       "set                      7\n",
       "collectorNumber        427\n",
       "castingcost            202\n",
       "rarity                   5\n",
       "cardTypeTextId          24\n",
       "subtypeTextId          439\n",
       "altDeckLimit             1\n",
       "linkedFaceType           5\n",
       "isSecondaryCard          1\n",
       "isToken                  1\n",
       "IsDigitalOnly            1\n",
       "watermark               26\n",
       "RebalancedCardLink     178\n",
       "altTitleId               7\n",
       "IsRebalanced             1\n",
       "title                 2158\n",
       "flavor                1015\n",
       "cardTypeText            24\n",
       "subtypeText            439\n",
       "dtype: int64"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for column in card_information.columns:\n",
    "#     print(column)\n",
    "#     print('\\t', card_information[column].nunique())\n",
    "\n",
    "card_information.nunique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analytics():\n",
    "    json = request_json('analytics', False)\n",
    "\n",
    "    # Separate into data and medatada (unused)\n",
    "    # metadata = json['metadata']\n",
    "    df = pd.json_normalize(json['data']).T\n",
    "\n",
    "    # Nested list with two levels\n",
    "    level_1 = ['games', 'wins', 'check', 'copies']\n",
    "    level_2 = ['copies_1', 'copies_2', 'copies_3', 'copies_4']\n",
    "\n",
    "    # Unnest the list in stages\n",
    "    df[level_1] = pd.DataFrame(df.explode(0)[0].to_list(), index=df.index)\n",
    "    df[level_2] = pd.DataFrame(df.copies.to_list(), index=df.index)\n",
    "\n",
    "    # Remove redundant columns, fill NaN with zeros and transform to int\n",
    "    df.drop([0, 'check', 'copies'], axis = 'columns', inplace = True)\n",
    "    df.fillna(0, inplace = True)\n",
    "    df = df.astype('int64')\n",
    "\n",
    "    return df\n",
    "\n",
    "analytics = analytics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analytics['check'] = analytics.loc[:, 'copies_1':'copies_4'].sum(axis=1) == analytics.games\n",
    "analytics.check.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

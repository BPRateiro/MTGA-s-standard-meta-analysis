{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports and endpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 100)\n",
    "from time import sleep\n",
    "\n",
    "urls = {\n",
    "    'api' : 'https://api.mtga.untapped.gg/api/v1/',\n",
    "    'json' : 'https://mtgajson.untapped.gg/v1/latest/',\n",
    "}\n",
    "\n",
    "endpoints = {\n",
    "    'active': ('api', 'meta-periods/active'),\n",
    "    'analytics': ('api', 'analytics/query/card_stats_by_archetype_event_and_scope_free/ALL?MetaPeriodId='),\n",
    "    'cards': ('json', 'cards.json'),\n",
    "    'text': ('json', 'loc_en.json'),\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'authority': 'api.mtga.untapped.gg',\n",
    "    'accept': '*/*',\n",
    "    'accept-language': 'en-US,en;q=0.9,pt;q=0.8',\n",
    "    'if-none-match': '\"047066ff947f01e9e609ca4cf0d6c0a6\"',\n",
    "    'origin': 'https://mtga.untapped.gg',\n",
    "    'referer': 'https://mtga.untapped.gg/',\n",
    "    'sec-ch-ua': '\"Google Chrome\";v=\"111\", \"Not(A:Brand\";v=\"8\", \"Chromium\";v=\"111\"',\n",
    "    'sec-ch-ua-mobile': '?0',\n",
    "    'sec-ch-ua-platform': '\"Windows\"',\n",
    "    'sec-fetch-dest': 'empty',\n",
    "    'sec-fetch-mode': 'cors',\n",
    "    'sec-fetch-site': 'same-site',\n",
    "    'user-agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/111.0.0.0 Safari/537.36',\n",
    "}\n",
    "\n",
    "def request(keyword, send_headers=True, format=''):\n",
    "    'Returns JSON from corresponding keyword'\n",
    "\n",
    "    url_kw, endpoint = endpoints[keyword]\n",
    "    url = urls[url_kw]\n",
    "    \n",
    "    sleep(1) # :)\n",
    "    if send_headers:\n",
    "        return requests.get(url+endpoint+format, headers).json()\n",
    "    else:\n",
    "        return requests.get(url+endpoint+format).json()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355 ['MID', 'VOW', 'NEO', 'SNC', 'DMU', 'BRO', 'ONE', 'MOM']\n"
     ]
    }
   ],
   "source": [
    "def request_active():\n",
    "    'Returns format ID and lists of standard legal sets'\n",
    "    latest = dict()\n",
    "\n",
    "    # Extracting information from the lastest standard BO1 format\n",
    "    for format in request('active'):\n",
    "        if format['event_name'] == 'Ladder':\n",
    "            latest = format\n",
    "\n",
    "    return str(latest['id']), latest['legal_sets']\n",
    "\n",
    "format_id, legal_sets = request_active()\n",
    "print(format_id, legal_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_cards(sets):\n",
    "    'Returns transformed cards dataframe'\n",
    "    df = pd.DataFrame(request('cards'))\n",
    "\n",
    "    # Ony bother with standard legal cards\n",
    "    df = df[df.set.isin(sets)]\n",
    "\n",
    "    # Remove duplicates by considering only the latest reprint\n",
    "    gb = df.groupby('titleId').agg({'grpid':'max'})\n",
    "    df = df[df.grpid.isin(gb.grpid)]\n",
    "\n",
    "    return df.set_index('grpid')\n",
    "\n",
    "cards = request_cards(legal_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def request_text():\n",
    "    'Returns card text dataframe'\n",
    "    df = pd.DataFrame(request('text')).set_index('id')\n",
    "\n",
    "    # Collapse columns raw and text, prioritizing raw\n",
    "    df.loc[~df.raw.isna(), 'text'] = df.raw\n",
    "    df.drop('raw', axis='columns', inplace=True)\n",
    "\n",
    "    return df\n",
    "\n",
    "text = request_text()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Card information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_card_information(sets):\n",
    "    \"Combine cards and text into format context\"    \n",
    "    text = request_text()\n",
    "    cards = request_cards(sets)\n",
    "\n",
    "    # Card columns mappable to text\n",
    "    text_columns = ['titleId', 'flavorId', 'cardTypeTextId', 'subtypeTextId']\n",
    "\n",
    "    # Additional transformed columns\n",
    "    transformed = (\n",
    "        cards[text_columns]\n",
    "        .applymap(lambda x: text.loc[x].values[0], na_action='ignore')\n",
    "        .rename(columns={column: column[:-2] for column in text_columns}) # Remove Id\n",
    "    )\n",
    "    cards = cards.join(transformed)\n",
    "\n",
    "    # Remove undesirable columns and change index to titleId\n",
    "    cards = cards.dropna(how='all', axis='columns')\n",
    "    ignore = [ # These don't seem useful\n",
    "        'collectorMax', \n",
    "        'frameColors',\n",
    "        'rawFrameDetails',\n",
    "        'frameDetails',\n",
    "        'grpid',\n",
    "        'altDeckLimit',\n",
    "        'IsRebalanced',\n",
    "        'isToken',\n",
    "        'IsDigitalOnly',\n",
    "        'linkedFaceType',\n",
    "        'cardTypeTextId',\n",
    "        'watermark',\n",
    "        'RebalancedCardLink',\n",
    "        'flavorId',\n",
    "        'subtypeTextId',\n",
    "        'collectorNumber',\n",
    "        'artistCredit',\n",
    "        'altTitleId',\n",
    "        'isSecondaryCard',\n",
    "    ]\n",
    "    problematic = [ # Still work to be done here\n",
    "        'abilities', \n",
    "        'abilityIdToLinkedTokenGrpId', \n",
    "        'hiddenAbilities',\n",
    "        'types',\n",
    "        'subtypes',\n",
    "        'supertypes',\n",
    "        'colors',\n",
    "        'colorIdentity',\n",
    "        'linkedFaces',\n",
    "    ]\n",
    "    cards = (cards.reset_index()\n",
    "                  .set_index('titleId')\n",
    "                  .drop(ignore + problematic, axis = 'columns'))\n",
    "\n",
    "    return cards\n",
    "\n",
    "card_information = get_card_information(legal_sets)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'b': 1687, 'g': 6825, 'p': 39378, 's': 3731}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def request_analytics(format):\n",
    "    json = request('analytics', False, format)\n",
    "\n",
    "    # Separate into data and medatada\n",
    "    metadata = json['metadata']\n",
    "    df = pd.json_normalize(json['data']).T\n",
    "\n",
    "    # Number of games per tier\n",
    "    games = {tier[0]: metadata['games'][tier]['ALL'] \n",
    "             for tier in metadata['games']}\n",
    "\n",
    "    # Nested list with two levels\n",
    "    level_1 = ['games', 'wins', 'check', 'copies']\n",
    "    level_2 = ['copies_1', 'copies_2', 'copies_3', 'copies_4']\n",
    "\n",
    "    # Unnest the list in stages\n",
    "    # When we have a new set, sometimes Untapped chooses to mix BO1 and BO3 statistics\n",
    "    # Thus we make sure to only get BO1 statistics for consistency.\n",
    "    df[level_1] = pd.DataFrame(df.explode(0)[0].to_list(), index=df.index).iloc[:, :4]\n",
    "    df[level_2] = pd.DataFrame(df.copies.to_list(), index=df.index)\n",
    "\n",
    "    # Remove redundant columns and fill NaN with zeros \n",
    "    df.drop([0, 'check', 'copies'], axis = 'columns', inplace = True)\n",
    "    df.fillna(0, inplace = True)\n",
    "\n",
    "    # Transform dtypes to int, reset index and rename tiers\n",
    "    df = (df.astype('int64')\n",
    "            .reset_index()\n",
    "            .rename(columns={'index':'raw'}))\n",
    "    \n",
    "    # Split raw column into multiple\n",
    "    df[['titleId', 'archetypeId', 'tier']] = df.raw.str.split('.', expand=True)\n",
    "\n",
    "    # Record only consolidated data by archetype and change index to titleId\n",
    "    df = (df[df.archetypeId == 'ALL']\n",
    "            .drop(['raw', 'archetypeId'], axis=1)\n",
    "            .set_index('titleId'))\n",
    "    df.index = df.index.astype('int64')\n",
    "    \n",
    "    # Time stamp and format\n",
    "    df.insert(0, 'dt_analytics', pd.Timestamp.today().strftime('%Y-%m-%d'))\n",
    "    df.insert(1, 'format', format)\n",
    "    \n",
    "    return df, games\n",
    "\n",
    "analytics, no_games = request_analytics(format_id)\n",
    "no_games"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ABT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def abt(format, sets, tier='ALL', full_report=False):\n",
    "    \"Full dataframe for a given query\"\n",
    "    card_information = get_card_information(sets)\n",
    "    analytics, games = request_analytics(format)\n",
    "\n",
    "    # Choose either aggregate statistics per tier or single one\n",
    "    # Use if clause to calculate 'included' statistic\n",
    "    if tier == 'ALL': # Aggregate games statistics\n",
    "        agg_dict = {column : 'sum' \n",
    "                    if column not in ['dt_analytics', 'format', 'tier']\n",
    "                    else 'max'\n",
    "                    for column in analytics.columns}\n",
    "        analytics = analytics.groupby('titleId').agg(agg_dict)\n",
    "        analytics.tier = 'ALL'\n",
    "        analytics['included'] = analytics.games/sum(games.values())\n",
    "    else:\n",
    "        analytics = analytics[analytics.tier == tier]\n",
    "        analytics['included'] = analytics.games/games[tier]\n",
    "\n",
    "    # Merge analytics and card information\n",
    "    merged = (analytics.reset_index()\n",
    "                       .merge(card_information.reset_index(),\n",
    "                              how='left', \n",
    "                              on='titleId')\n",
    "                       .set_index('titleId'))\n",
    "    \n",
    "    # Winrate\n",
    "    merged['winrate'] = merged.wins/merged.games\n",
    "\n",
    "    # Quantity\n",
    "    copies = ['copies_1', 'copies_2', 'copies_3', 'copies_4']\n",
    "    merged['quantity'] = merged[copies].idxmax(axis=1)\n",
    "    \n",
    "    if full_report:\n",
    "        return merged\n",
    "    else:\n",
    "        return merged[['title',\n",
    "                       'set',\n",
    "                       'rarity', \n",
    "                       'castingcost', \n",
    "                       'winrate', \n",
    "                       'games', \n",
    "                       'included', \n",
    "                       'quantity']]\n",
    "    \n",
    "df_abt = abt(format_id, legal_sets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
